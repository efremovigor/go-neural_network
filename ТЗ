-1. На вход идут неироны с int64 значениями.
2. на первой итерации обучения выставляются рандомные веса от 0.00 до 1
3. внутренний слой неиронов имеет такое-жу кол-во неиронов как и внешний
4. на этапе обучения перемножаются значения каждого внешнего неирона на вес связи, и далее используется полученное значение x в формуле 1 / (1 + e^−x) = (где e = 2,71828182846 )
 тем самым получая значение внутреннего неирона
5. Берется значение каждого внутреннего неирона умножается на его вес , и далее используется полученное значение x в формуле 1 / (1 + e^−x) = (где e = 2,71828182846 )
тем самым получая значение результирующего неирона
6. Выщитывается число ошибки - значение неирона - ожидаемого значения
7. Выщитывается дельта весов - число ошибки умноженая на производную значение нейрона - err * neural * (1 - neural)
8. Получаем новый вес внутреннего неирона - текущий вес - значение неирона * дельта весов * лернинг рейт (ставится как константа для скорости обучения(0.1))
9. Получаем ошибку внутреннего неирона - новый вес вн. неирона * дельту весов

